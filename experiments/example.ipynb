{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32ec4e1",
   "metadata": {},
   "source": [
    "# Leveraging PINNs For Multi-Dimensional Pricing Problems \n",
    "#### Author: JP Melo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408abab0",
   "metadata": {},
   "source": [
    "This thesis is focused on the application of Physics-Informed Neural Networks (PINNs) to solve multi-dimensional pricing problems in finance. The equation we attempt to solve is described below.\n",
    "\n",
    "### **Equation**\n",
    "First, we define the scaled variables \n",
    "$$\n",
    "  x_i \\;=\\; \\ln\\!\\Bigl(\\frac{S_i}{K}\\Bigr),\n",
    "  \\quad \n",
    "  u(\\tau, x_1, \\dots, x_d) \\;=\\; \\frac{V\\bigl(t,S_1,\\dots,S_d\\bigr)}{K}\n",
    "  \\quad\\text{with}\\quad \n",
    "  \\tau \\;=\\; T - t.\n",
    "$$\n",
    "\n",
    "Under risk-neutral pricing in backward time $\\tau$, the function \n",
    "$u(\\tau, x_1, \\dots, x_d)$ satisfies the PDE\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial \\tau} \\;=\\;\n",
    "\\frac{1}{2}\\sum_{i=1}^d \n",
    "\\sigma_i^{2}\\!\\left(\n",
    "\\frac{\\partial^{2}u}{\\partial x_i^{2}}\n",
    "-\\frac{\\partial u}{\\partial x_i}\\right)\n",
    "\\;+\\;\n",
    "\\frac{1}{2}\\sum_{i=1}^d\\sum_{j=1}^d\n",
    "\\sigma_i\\sigma_j\\rho_{ij}\\,\n",
    "\\frac{\\partial^{2}u}{\\partial x_i\\,\\partial x_j}\n",
    "\\;+\\;\n",
    "r\\sum_{i=1}^d\\frac{\\partial u}{\\partial x_i}\n",
    "\\;-\\;\n",
    "r\\,u .\n",
    "$$\n",
    "\n",
    "### **Boundary Conditions**\n",
    "\n",
    "**Bottom boundary**  \n",
    "For very small $S_i$ i.e. $x_i \\to -\\infty$, one commonly imposes (1 asset)\n",
    "$$\n",
    "    -\\frac{\\partial u}{\\partial \\tau} - ru \\;=\\; 0.\n",
    "$$\n",
    "\n",
    "For the multi-asset case, the k'th lower boundary condition is given by\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial \\tau} \\;=\\;\n",
    "\\frac{1}{2}\\sum_{\\substack{i=1 \\\\ i\\neq k}}^d \n",
    "\\sigma_i^{2}\\!\\left(\n",
    "\\frac{\\partial^{2}u}{\\partial x_i^{2}}\n",
    "-\\frac{\\partial u}{\\partial x_i}\\right)\n",
    "\\;+\\;\n",
    "\\frac{1}{2}\\sum_{\\substack{i=1 \\\\ i\\neq k}}^d\n",
    "      \\sum_{\\substack{j=1 \\\\ j\\neq k}}^d\n",
    "\\sigma_i\\sigma_j\\rho_{ij}\\,\n",
    "\\frac{\\partial^{2}u}{\\partial x_i\\,\\partial x_j}\n",
    "\\;+\\;\n",
    "r\\sum_{\\substack{i=1 \\\\ i\\neq k}}^d\n",
    "\\frac{\\partial u}{\\partial x_i}\n",
    "\\;-\\;\n",
    "r\\,u .\n",
    "$$\n",
    "\n",
    "**Top boundary**  \n",
    "For very large $S_i$ i.e. $x_i \\to +\\infty$, assume asymptotically linear behavior in $S_i$,\n",
    "which translates to the following expression in the dimensionless case (1 asset):\n",
    "$$\n",
    "   \\frac{\\partial^2 u}{\\partial x_i^2}-\\frac{\\partial u}{\\partial x_i} = 0\n",
    "$$\n",
    "\n",
    "The generalization for the multi-asset case is straightforward is presented below:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial \\tau} \\;=\\;\n",
    "\\frac{1}{2}\\sum_{\\substack{i=1 \\\\ i\\neq k}}^d \n",
    "\\sigma_i^{2}\\!\\left(\n",
    "\\frac{\\partial^{2}u}{\\partial x_i^{2}}\n",
    "-\\frac{\\partial u}{\\partial x_i}\\right)\n",
    "\\;+\\;\n",
    "\\frac{1}{2}\\sum_{\\substack{i=1 \\\\ i\\neq k}}^d\n",
    "      \\sum_{\\substack{j=1 \\\\ j\\neq k}}^d\n",
    "\\sigma_i\\sigma_j\\rho_{ij}\\,\n",
    "\\frac{\\partial^{2}u}{\\partial x_i\\,\\partial x_j}\n",
    "\\;+\\;\n",
    "r\\sum_{i=1}^d\\frac{\\partial u}{\\partial x_i}\n",
    "\\;-\\;\n",
    "r\\,u .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50527de",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d74c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josemelo/Desktop/master/tesis/codes/.conda/lib/python3.11/site-packages/kfac/base_preconditioner.py:15: UserWarning: NVIDIA Apex is not installed or was not installed with --cpp_ext. Falling back to PyTorch flatten and unflatten.\n",
      "  from kfac.distributed import get_rank\n"
     ]
    }
   ],
   "source": [
    "from derpinns.nn import *\n",
    "from derpinns.utils import *\n",
    "from derpinns.trainer import *\n",
    "import torch\n",
    "import kfac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70ad0c",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1176864d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Global parameters\n",
    "assets = 3\n",
    "sampler = \"pseudo\"               # [\"pseudo\", \"LHS\", \"Halton\", \"Hammersley\", \"Sobol\"]:\n",
    "nn_shape = \"64x3\"               # n_assets input layer + 64 neurons, 3 hidden layers + 1 output layer\n",
    "device = torch.device(\"cpu\")    # cpu, cuda or mps\n",
    "dtype = torch.float32\n",
    "\n",
    "# Define option valuation params\n",
    "params = OptionParameters(\n",
    "    n_assets=assets,\n",
    "    tau=1.0,\n",
    "    sigma=np.array([0.2] * assets),\n",
    "    rho=np.eye(assets) + 0.25 * (np.ones((assets, assets)) - np.eye(assets)),\n",
    "    r=0.05,\n",
    "    strike=100,\n",
    "    payoff=payoff\n",
    ")\n",
    "\n",
    "# Build the net to be used\n",
    "model = build_nn(\n",
    "    nn_shape=nn_shape,\n",
    "    input_dim=assets,\n",
    "    dtype=torch.float32\n",
    ").apply(weights_init).to(device)\n",
    "\n",
    "### Other possible net models\n",
    "# model = NNAnzats(n_layers=3, input_dim=assets+1,hidden_dim=64, output_dim=1).apply(weights_init).to(device)\n",
    "# model = SPINN(n_layers=3, input_dim=assets+1, hidden_dim=32, output_dim=1).apply(weights_init).to(device)\n",
    "# model = NNWithFourier(n_layers=3, input_dim=assets+1, hidden_dim=64, output_dim=1).apply(weights_init).to(device)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdffad9",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "For training, different optimizers are used in order to get better accuracy as stated in [this article](https://arxiv.org/pdf/2402.01868)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5452c",
   "metadata": {},
   "source": [
    "### Adam Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c1354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam training:  30%|██▉       | 296/1000 [01:22<03:24,  3.44it/s, Interior=0.001252, Boundary=0.001156, Initial=0.013409, Total=0.015817, Max Error=48.8054199219, L2 Error=0.0691072568] Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x107cf6f50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/josemelo/Desktop/master/tesis/codes/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Adam training:  34%|███▍      | 338/1000 [01:34<03:20,  3.30it/s, Interior=0.001092, Boundary=0.000932, Initial=0.006360, Total=0.008384, Max Error=56.5372924805, L2 Error=0.0798415318]"
     ]
    }
   ],
   "source": [
    "# Set the training parameters\n",
    "batch_size = 500\n",
    "total_iter = 1_000\n",
    "boundary_samples = 20_000\n",
    "interior_samples = boundary_samples*assets*2\n",
    "initial_samples = boundary_samples*assets*2\n",
    "\n",
    "# Create dataset to traing over\n",
    "dataset = SampledDataset(\n",
    "    params, interior_samples, initial_samples, boundary_samples, sampler, dtype, device)\n",
    "\n",
    "# Set optimizer and training function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "preconditioner = kfac.preconditioner.KFACPreconditioner(model)\n",
    "\n",
    "# Set the training function\n",
    "closure = DimlessBS()\\\n",
    "    .with_dataset(dataset, loader_opts={'batch_size': batch_size, \"shuffle\": True, \"pin_memory\": True})\\\n",
    "    .with_model(model)\\\n",
    "    .with_device(device)\\\n",
    "    .with_dtype(dtype)\n",
    "\n",
    "trainer = PINNTrainer()\\\n",
    "    .with_optimizer(optimizer)\\\n",
    "    .with_device(device)\\\n",
    "    .with_dtype(dtype)\\\n",
    "    .with_training_step(closure)\\\n",
    "    .with_preconditioner(preconditioner)\\\n",
    "    .with_epochs(total_iter)\\\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524726b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = trainer.closure.get_state()\n",
    "plot_loss(state, smooth=True, smooth_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaec2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_with_mc(model, params, n_prices=200,\n",
    "                          n_simulations=10_000, dtype=dtype, device=device, seed=42)['l2_rel_error']\n",
    "print(\"L2 Error: \", results*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1c27f",
   "metadata": {},
   "source": [
    "### LBFGS Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_samples = 2_000\n",
    "interior_samples = boundary_samples*assets*2\n",
    "initial_samples = boundary_samples*assets*2\n",
    "\n",
    "# We create new samples\n",
    "dataset = SampledDataset(\n",
    "    params, interior_samples, initial_samples, boundary_samples, sampler, dtype, device)\n",
    "\n",
    "optimizer = LBFGS(\n",
    "    model.parameters(),\n",
    "    max_eval=1_000,\n",
    "    max_iter=1_000,\n",
    "    line_search_fn=\"strong_wolfe\",\n",
    ")\n",
    "batch_size = len(dataset) # we use all samples\n",
    "\n",
    "closure = closure.with_dataset(\n",
    "    dataset, loader_opts={'batch_size': batch_size, \"shuffle\": True, \"pin_memory\": True})\n",
    "\n",
    "trainer = trainer.with_optimizer(optimizer).with_training_step(closure)\n",
    "trainer.train()\n",
    "\n",
    "state = closure.get_state()\n",
    "plot_loss(state, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_with_mc(model, params, n_prices=200,\n",
    "                          n_simulations=10_000, dtype=dtype, device=device)['l2_rel_error']\n",
    "print(\"L2 Error: \", results*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
